{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://cedric.cnam.fr/vertigo/Cours/ml2/tpDeepLearning1.html\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('TKAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7.195, 3.841), dpi=100)\n",
    "for i in range(200):\n",
    "    plt.subplot(10,20,i+1)\n",
    "    plt.imshow(X_train[i,:].reshape([28,28]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "K=10\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, K)\n",
    "Y_test = np_utils.to_categorical(y_test, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X): \n",
    "    # Input matrix X of size Nbxd\n",
    "    E = np.exp(X)\n",
    "    return (E.T / np.sum(E,axis=1)).T\n",
    "\n",
    "def forward(images, W, b):             \n",
    "    pred = np.matmul(images, W) + b\n",
    "    return softmax(pred)\n",
    "\n",
    "def accuracy(W, b, images, labels):\n",
    "    pred = forward(images, W,b )  \n",
    "    return np.where( pred.argmax(axis=1) != labels.argmax(axis=1) , 0.,1.).mean()*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = X_train.shape[1]\n",
    "N = X_train.shape[0]\n",
    "numIt = 20\n",
    "\n",
    "W = np.zeros((d,K)) \n",
    "biais = np.zeros((1,K))\n",
    "eta = 1e-1\n",
    "\n",
    "batch_size = 100\n",
    "nb_batches = int(float(N) / batch_size)\n",
    "\n",
    "gradW = np.zeros((d,K))\n",
    "gradb = np.zeros((1,K))\n",
    "\n",
    "for it in range(numIt):\n",
    "    for b in range(nb_batches):\n",
    "        # FORWARD\n",
    "        pred = forward(X_train[b*batch_size:(b+1)*batch_size,:], W,biais)      \n",
    "        val = pred - Y_train[b*batch_size:(b+1)*batch_size,:]  \n",
    "        # BACKWARD \n",
    "        gradW = 1.0/batch_size * np.matmul(np.transpose(X_train[b*batch_size:(b+1)*batch_size,:]),val)\n",
    "        gradb = 1.0/batch_size * (val.sum(axis=0)).reshape((1,10))  \n",
    "\n",
    "        W = W - eta * gradW\n",
    "        biais = biais - eta * gradb\n",
    "\n",
    "    print(\"epoch \", it, \"accurcy train=\",accuracy(W, biais, X_train, Y_train), \"accurcy test=\",accuracy(W, biais, X_test, Y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
